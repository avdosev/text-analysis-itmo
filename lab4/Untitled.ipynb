{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/projects/itmo/text-anal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore') \n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.19391431e-02 -1.30229220e-02  3.06631625e-03 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.75315589e-01 -2.30471697e-03 -1.09591149e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.15469089e-02 -1.27656385e-05 -1.42107129e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 1.79358423e-01  4.50087674e-02  9.15019736e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.13700098e-02 -3.05269305e-02 -7.54913837e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.45927663e-02 -1.08351810e-02  1.37498990e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "(300, 40)\n"
     ]
    }
   ],
   "source": [
    "shape = (300, 40)\n",
    "\n",
    "def fix_sized(array, needed_size, vector_size): \n",
    "    while len(array) < needed_size:\n",
    "        array.append([0]*vector_size)\n",
    "    return np.array(array[:needed_size]).T\n",
    "\n",
    "def vectorize_seq(s):\n",
    "    return fix_sized([ft.get_word_vector(w) for w in str(s).split(' ')], *shape[::-1])\n",
    "\n",
    "print(vectorize_seq('raz dvas trus'))\n",
    "print(vectorize_seq('raz dvas trus').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       textID                                               text sentiment\n",
      "0  98e200a8da                              Because I love my job  positive\n",
      "1  4e2a0dbf92                             I hate having headrush  negative\n",
      "2  9bfe71fa3f                      blogging..it`s my new passion  positive\n",
      "3  f358968122  I have to go clothes shopping tomorrow  I hate...  negative\n",
      "4  f38b1d3dff   Ur going 2 get tired of hearing from me, but ...   neutral\n",
      "19236\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/tweets_train.csv')\n",
    "test = pd.read_csv('data/tweets_test.csv')\n",
    "print(train.head())\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0                              Because I love my job\n",
      "1                             I hate having headrush\n",
      "2                      blogging..it`s my new passion\n",
      "3  I have to go clothes shopping tomorrow  I hate...\n",
      "4   Ur going 2 get tired of hearing from me, but ...\n",
      "   sentiment_positive  sentiment_negative  sentiment_neutral\n",
      "0                   1                   0                  0\n",
      "1                   0                   1                  0\n",
      "2                   1                   0                  0\n",
      "3                   0                   1                  0\n",
      "4                   0                   0                  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-6a703b95e02f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n"
     ]
    }
   ],
   "source": [
    "X = train[['text']]\n",
    "y = train[['sentiment']]\n",
    "for label in ['positive', 'negative', 'neutral']:\n",
    "    y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n",
    "y.drop(['sentiment'], axis=1, inplace=True)\n",
    "\n",
    "# y = y.apply\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max(len(item['text'].split(' ')) for item in X.iloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1              [-1, 200, 40]          60,200\n",
      "               ELU-2              [-1, 200, 40]               0\n",
      "            Conv1d-3              [-1, 100, 40]          20,100\n",
      "               ELU-4              [-1, 100, 40]               0\n",
      "           Flatten-5                 [-1, 4000]               0\n",
      "            Linear-6                  [-1, 300]       1,200,300\n",
      "               ELU-7                  [-1, 300]               0\n",
      "            Linear-8                    [-1, 3]             903\n",
      "               ELU-9                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 1,281,503\n",
      "Trainable params: 1,281,503\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.22\n",
      "Params size (MB): 4.89\n",
      "Estimated Total Size (MB): 5.15\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyModel(t.nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.stack = t.nn.Sequential(\n",
    "            t.nn.Conv1d(shape[0], 200, 1),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Conv1d(200, 100, 1),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Flatten(),\n",
    "            t.nn.Linear(4000, 300),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Linear(300, 3),\n",
    "            t.nn.ELU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "    \n",
    "model = MyModel(shape)\n",
    "summary(model, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0128,  0.1005,  0.1389,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0070, -0.1526,  0.0809,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0022,  0.0444,  0.0961,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0084,  0.6786,  0.0484,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0083, -0.1639, -0.0927,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0347,  0.0854,  0.0024,  ...,  0.0000,  0.0000,  0.0000]]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset): \n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = [vectorize_seq(item['text']).astype(np.float32) for item in x.iloc]\n",
    "        self.y = y\n",
    "        self.size = len(x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = t.from_numpy(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            y = t.from_numpy(np.array([np.argmax(self.y.iloc[idx].to_numpy())]))\n",
    "            return (x, y)\n",
    "        return x\n",
    "\n",
    "train_dataset = TextDataset(X, y)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.102338      0\n",
      "model saved\n",
      "epoch: 1 loss: 0.849264      0\n",
      "model saved\n",
      "epoch: 2 loss: 0.819758      0\n",
      "model saved\n",
      "epoch: 3 loss: 0.804996      0\n",
      "model saved\n",
      "epoch: 4 loss: 0.786503      0\n",
      "model saved\n",
      "epoch: 5 loss: 0.702900      0\n",
      "model saved\n",
      "epoch: 6 loss: 0.770754      0\n",
      "epoch: 7 loss: 0.766972      0\n",
      "epoch: 8 loss: 0.711971      0\n",
      "epoch: 9 loss: 0.708953      0\n",
      "epoch: 10 loss: 0.687942      0\n",
      "model saved\n",
      "epoch: 11 loss: 0.609004      0\n",
      "model saved\n",
      "epoch: 12 loss: 0.573422      0\n",
      "model saved\n",
      "epoch: 13 loss: 0.592827      0\n",
      "epoch: 14 loss: 0.556821      0\n",
      "model saved\n",
      "epoch: 15 loss: 0.562782      0\n",
      "epoch: 16 loss: 0.591676      0\n",
      "epoch: 17 loss: 0.515409      0\n",
      "model saved\n",
      "epoch: 18 loss: 0.479677      0\n",
      "model saved\n",
      "epoch: 19 loss: 0.502862      0\n",
      "epoch: 20 loss: 0.465388      0\n",
      "model saved\n",
      "epoch: 21 loss: 0.490328      0\n",
      "epoch: 22 loss: 0.413608      0\n",
      "model saved\n",
      "epoch: 23 loss: 0.423320      0\n",
      "epoch: 24 loss: 0.395913      0\n",
      "model saved\n",
      "epoch: 25 loss: 0.407017      0\n",
      "epoch: 26 loss: 0.342006      0\n",
      "model saved\n",
      "epoch: 27 loss: 0.364729      0\n",
      "epoch: 28 loss: 0.338452      0\n",
      "model saved\n",
      "epoch: 29 loss: 0.357682      0\n",
      "best loss: 0.338451623916626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (stack): Sequential(\n",
       "    (0): Conv1d(300, 200, kernel_size=(1,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(200, 100, kernel_size=(1,), stride=(1,))\n",
       "    (3): ELU(alpha=1.0)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "    (5): Linear(in_features=4000, out_features=300, bias=True)\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Linear(in_features=300, out_features=3, bias=True)\n",
       "    (8): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# loss_function = t.nn.NLLLoss()\n",
    "loss_function = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "max_epochs = 30\n",
    "batch_size = 400\n",
    "_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "min_loss = 300\n",
    "\n",
    "m_path = 'data/torch_model_state.bin'\n",
    "for i in range(0, max_epochs):\n",
    "    for batch, (b_X, b_Y) in enumerate(_train):\n",
    "        optimizer.zero_grad()\n",
    "        b_ans = model.forward(b_X)\n",
    "        loss = loss_function(b_ans, b_Y.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"epoch: {i} loss: {loss:>7f}  {current:>5d}\")\n",
    "            if loss < min_loss:\n",
    "                t.save(model.state_dict(), m_path)\n",
    "                min_loss = loss\n",
    "                print('model saved')\n",
    "print('best loss:', min_loss)\n",
    "model.load_state_dict(t.load(m_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = TextDataset(test[['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = DataLoader(x_test)\n",
    "result=[]\n",
    "for x in _data:\n",
    "    result.append(model(x).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.argmax(result, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {\n",
    "    0: 'positive',\n",
    "    1: 'negative',\n",
    "    2: 'neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'textID': test['textID'],\n",
    "    'sentiment': [mp[item] for item in res.astype(int).reshape(-1)]\n",
    "}).to_csv('data/submissions/4-neural-network-13.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
