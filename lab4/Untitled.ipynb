{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/projects/itmo/text-anal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore') \n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.19391431e-02 -1.30229220e-02  3.06631625e-03 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.75315589e-01 -2.30471697e-03 -1.09591149e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.15469089e-02 -1.27656385e-05 -1.42107129e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 1.79358423e-01  4.50087674e-02  9.15019736e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.13700098e-02 -3.05269305e-02 -7.54913837e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.45927663e-02 -1.08351810e-02  1.37498990e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "(300, 40)\n"
     ]
    }
   ],
   "source": [
    "shape = (300, 40)\n",
    "\n",
    "def fix_sized(array, needed_size, vector_size): \n",
    "    while len(array) < needed_size:\n",
    "        array.append([0]*vector_size)\n",
    "    return np.array(array[:needed_size]).T\n",
    "\n",
    "def vectorize_seq(s):\n",
    "    return fix_sized([ft.get_word_vector(w) for w in s.split(' ')], *shape[::-1])\n",
    "\n",
    "print(vectorize_seq('raz dvas trus'))\n",
    "print(vectorize_seq('raz dvas trus').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       textID                                               text sentiment\n",
      "0  98e200a8da                              Because I love my job  positive\n",
      "1  4e2a0dbf92                             I hate having headrush  negative\n",
      "2  9bfe71fa3f                      blogging..it`s my new passion  positive\n",
      "3  f358968122  I have to go clothes shopping tomorrow  I hate...  negative\n",
      "4  f38b1d3dff   Ur going 2 get tired of hearing from me, but ...   neutral\n",
      "19236\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/tweets_train.csv')\n",
    "test = pd.read_csv('data/tweets_test.csv')\n",
    "print(train.head())\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0                              Because I love my job\n",
      "1                             I hate having headrush\n",
      "2                      blogging..it`s my new passion\n",
      "3  I have to go clothes shopping tomorrow  I hate...\n",
      "4   Ur going 2 get tired of hearing from me, but ...\n",
      "   sentiment_positive  sentiment_negative  sentiment_neutral\n",
      "0                   1                   0                  0\n",
      "1                   0                   1                  0\n",
      "2                   1                   0                  0\n",
      "3                   0                   1                  0\n",
      "4                   0                   0                  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-ef2431f6ce91>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n"
     ]
    }
   ],
   "source": [
    "X = train[['text']]\n",
    "y = train['sentiment']\n",
    "for label in ['positive', 'negative', 'neutral']:\n",
    "    y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n",
    "y.drop(['sentiment'], axis=1, inplace=True)\n",
    "\n",
    "y = y.apply\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max(len(item['text'].split(' ')) for item in X.iloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 10, 40]           3,010\n",
      "              ReLU-2               [-1, 10, 40]               0\n",
      "            Conv1d-3               [-1, 40, 38]           1,240\n",
      "         MaxPool1d-4               [-1, 40, 19]               0\n",
      "              ReLU-5               [-1, 40, 19]               0\n",
      "            Conv1d-6                [-1, 1, 17]             121\n",
      "              ReLU-7                [-1, 1, 17]               0\n",
      "           Flatten-8                   [-1, 17]               0\n",
      "            Linear-9                   [-1, 10]             180\n",
      "             ReLU-10                   [-1, 10]               0\n",
      "           Linear-11                    [-1, 3]              33\n",
      "          Softmax-12                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 4,584\n",
      "Trainable params: 4,584\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.09\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyModel(t.nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.stack = t.nn.Sequential(\n",
    "            t.nn.Conv1d(shape[0], 10, 1),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Conv1d(10, shape[1], 3),\n",
    "            t.nn.MaxPool1d(2),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Conv1d(shape[1], 1, 3),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Flatten(),\n",
    "            t.nn.Linear(17, 10),\n",
    "            t.nn.ReLU(),\n",
    "            t.nn.Linear(10, 3),\n",
    "            t.nn.Softmax(1),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "    \n",
    "model = MyModel(shape)\n",
    "summary(model, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0128,  0.1005,  0.1389,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0070, -0.1526,  0.0809,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0022,  0.0444,  0.0961,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0084,  0.6786,  0.0484,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0083, -0.1639, -0.0927,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0347,  0.0854,  0.0024,  ...,  0.0000,  0.0000,  0.0000]]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset): \n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = [vectorize_seq(item['text']).astype(np.float32) for item in x.iloc]\n",
    "        self.y = y\n",
    "        self.size = len(x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = t.from_numpy(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            y = t.from_numpy(np.array([np.argmax(self.y.iloc[idx].to_numpy())]))\n",
    "            return (x, y)\n",
    "        return x\n",
    "\n",
    "train_dataset = TextDataset(X, y)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: -0.336119      0\n",
      "epoch: 1 loss: -0.335772      0\n",
      "epoch: 2 loss: -0.337484      0\n",
      "epoch: 3 loss: -0.335543      0\n",
      "epoch: 4 loss: -0.336603      0\n",
      "epoch: 5 loss: -0.338402      0\n",
      "epoch: 6 loss: -0.336466      0\n",
      "epoch: 7 loss: -0.338621      0\n",
      "epoch: 8 loss: -0.337014      0\n",
      "epoch: 9 loss: -0.336940      0\n",
      "epoch: 10 loss: -0.339467      0\n",
      "epoch: 11 loss: -0.338544      0\n",
      "epoch: 12 loss: -0.337507      0\n",
      "epoch: 13 loss: -0.337661      0\n",
      "epoch: 14 loss: -0.336857      0\n",
      "epoch: 15 loss: -0.339977      0\n",
      "epoch: 16 loss: -0.344898      0\n",
      "epoch: 17 loss: -0.342555      0\n",
      "epoch: 18 loss: -0.343795      0\n",
      "epoch: 19 loss: -0.348773      0\n",
      "epoch: 20 loss: -0.353991      0\n",
      "epoch: 21 loss: -0.364391      0\n",
      "epoch: 22 loss: -0.368166      0\n",
      "epoch: 23 loss: -0.397272      0\n",
      "epoch: 24 loss: -0.376043      0\n",
      "epoch: 25 loss: -0.400105      0\n",
      "epoch: 26 loss: -0.399972      0\n",
      "epoch: 27 loss: -0.406636      0\n",
      "epoch: 28 loss: -0.401746      0\n",
      "epoch: 29 loss: -0.428998      0\n",
      "epoch: 30 loss: -0.437731      0\n",
      "epoch: 31 loss: -0.430046      0\n",
      "epoch: 32 loss: -0.421166      0\n",
      "epoch: 33 loss: -0.440962      0\n",
      "epoch: 34 loss: -0.453714      0\n",
      "epoch: 35 loss: -0.434058      0\n",
      "epoch: 36 loss: -0.444787      0\n",
      "epoch: 37 loss: -0.471941      0\n",
      "epoch: 38 loss: -0.450519      0\n",
      "epoch: 39 loss: -0.466592      0\n",
      "epoch: 40 loss: -0.456577      0\n",
      "epoch: 41 loss: -0.454249      0\n",
      "epoch: 42 loss: -0.460295      0\n",
      "epoch: 43 loss: -0.431707      0\n",
      "epoch: 44 loss: -0.466024      0\n",
      "epoch: 45 loss: -0.476462      0\n",
      "epoch: 46 loss: -0.467993      0\n",
      "epoch: 47 loss: -0.472185      0\n",
      "epoch: 48 loss: -0.491568      0\n",
      "epoch: 49 loss: -0.483378      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (stack): Sequential(\n",
       "    (0): Conv1d(300, 10, kernel_size=(1,), stride=(1,))\n",
       "    (1): ReLU()\n",
       "    (2): Conv1d(10, 40, kernel_size=(3,), stride=(1,))\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): ReLU()\n",
       "    (5): Conv1d(40, 1, kernel_size=(3,), stride=(1,))\n",
       "    (6): ReLU()\n",
       "    (7): Flatten(start_dim=1, end_dim=-1)\n",
       "    (8): Linear(in_features=17, out_features=10, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=10, out_features=3, bias=True)\n",
       "    (11): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "loss_function = t.nn.NLLLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.0001)\n",
    "max_epochs = 50\n",
    "batch_size = 500\n",
    "_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "for i in range(0, max_epochs):\n",
    "    for batch, (b_X, b_Y) in enumerate(_train):\n",
    "        optimizer.zero_grad()\n",
    "        b_ans = model.forward(b_X)\n",
    "        loss = loss_function(b_ans, b_Y.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"epoch: {i} loss: {loss:>7f}  {current:>5d}\")\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
