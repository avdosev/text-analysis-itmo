{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/projects/itmo/text-anal/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttext.util.download_model('en', if_exists='ignore') \n",
    "ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch as t\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from torchsummary import summary\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.19391431e-02 -1.30229220e-02  3.06631625e-03 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.75315589e-01 -2.30471697e-03 -1.09591149e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 5.15469089e-02 -1.27656385e-05 -1.42107129e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " ...\n",
      " [ 1.79358423e-01  4.50087674e-02  9.15019736e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-5.13700098e-02 -3.05269305e-02 -7.54913837e-02 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 3.45927663e-02 -1.08351810e-02  1.37498990e-01 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n",
      "(300, 40)\n"
     ]
    }
   ],
   "source": [
    "shape = (300, 40)\n",
    "\n",
    "def fix_sized(array, needed_size, vector_size): \n",
    "    while len(array) < needed_size:\n",
    "        array.append([0]*vector_size)\n",
    "    return np.array(array[:needed_size]).T\n",
    "\n",
    "def vectorize_seq(s):\n",
    "    return fix_sized([ft.get_word_vector(w) for w in str(s).split(' ')], *shape[::-1])\n",
    "\n",
    "print(vectorize_seq('raz dvas trus'))\n",
    "print(vectorize_seq('raz dvas trus').shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       textID                                               text sentiment\n",
      "0  98e200a8da                              Because I love my job  positive\n",
      "1  4e2a0dbf92                             I hate having headrush  negative\n",
      "2  9bfe71fa3f                      blogging..it`s my new passion  positive\n",
      "3  f358968122  I have to go clothes shopping tomorrow  I hate...  negative\n",
      "4  f38b1d3dff   Ur going 2 get tired of hearing from me, but ...   neutral\n",
      "19236\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/tweets_train.csv')\n",
    "test = pd.read_csv('data/tweets_test.csv')\n",
    "print(train.head())\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0                              Because I love my job\n",
      "1                             I hate having headrush\n",
      "2                      blogging..it`s my new passion\n",
      "3  I have to go clothes shopping tomorrow  I hate...\n",
      "4   Ur going 2 get tired of hearing from me, but ...\n",
      "   sentiment_positive  sentiment_negative  sentiment_neutral\n",
      "0                   1                   0                  0\n",
      "1                   0                   1                  0\n",
      "2                   1                   0                  0\n",
      "3                   0                   1                  0\n",
      "4                   0                   0                  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-6a703b95e02f>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n"
     ]
    }
   ],
   "source": [
    "X = train[['text']]\n",
    "y = train[['sentiment']]\n",
    "for label in ['positive', 'negative', 'neutral']:\n",
    "    y[f'sentiment_{label}'] = (y['sentiment'] == label).astype(int)\n",
    "y.drop(['sentiment'], axis=1, inplace=True)\n",
    "\n",
    "# y = y.apply\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n"
     ]
    }
   ],
   "source": [
    "print(max(len(item['text'].split(' ')) for item in X.iloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1               [-1, 30, 40]           9,030\n",
      "               ELU-2               [-1, 30, 40]               0\n",
      "            Conv1d-3               [-1, 40, 38]           3,640\n",
      "         MaxPool1d-4               [-1, 40, 19]               0\n",
      "               ELU-5               [-1, 40, 19]               0\n",
      "            Conv1d-6                [-1, 1, 17]             121\n",
      "               ELU-7                [-1, 1, 17]               0\n",
      "           Flatten-8                   [-1, 17]               0\n",
      "            Linear-9                   [-1, 20]             360\n",
      "              ELU-10                   [-1, 20]               0\n",
      "           Linear-11                    [-1, 3]              63\n",
      "              ELU-12                    [-1, 3]               0\n",
      "================================================================\n",
      "Total params: 13,214\n",
      "Trainable params: 13,214\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 0.05\n",
      "Estimated Total Size (MB): 0.14\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyModel(t.nn.Module):\n",
    "    def __init__(self, shape):\n",
    "        super().__init__()\n",
    "        self.stack = t.nn.Sequential(\n",
    "            t.nn.Conv1d(shape[0], 30, 1),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Conv1d(30, shape[1], 3),\n",
    "            t.nn.MaxPool1d(2),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Conv1d(shape[1], 1, 3),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Flatten(),\n",
    "            t.nn.Linear(17, 20),\n",
    "            t.nn.ELU(),\n",
    "            t.nn.Linear(20, 3),\n",
    "            t.nn.ELU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.stack(X)\n",
    "    \n",
    "model = MyModel(shape)\n",
    "summary(model, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0128,  0.1005,  0.1389,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0070, -0.1526,  0.0809,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0022,  0.0444,  0.0961,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0084,  0.6786,  0.0484,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0083, -0.1639, -0.0927,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0347,  0.0854,  0.0024,  ...,  0.0000,  0.0000,  0.0000]]), tensor([0]))\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset): \n",
    "    def __init__(self, x, y=None):\n",
    "        self.x = [vectorize_seq(item['text']).astype(np.float32) for item in x.iloc]\n",
    "        self.y = y\n",
    "        self.size = len(x)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = t.from_numpy(self.x[idx])\n",
    "        if self.y is not None:\n",
    "            y = t.from_numpy(np.array([np.argmax(self.y.iloc[idx].to_numpy())]))\n",
    "            return (x, y)\n",
    "        return x\n",
    "\n",
    "train_dataset = TextDataset(X, y)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 1.070065      0\n",
      "epoch: 1 loss: 1.053776      0\n",
      "epoch: 2 loss: 0.980644      0\n",
      "epoch: 3 loss: 0.920470      0\n",
      "epoch: 4 loss: 0.887284      0\n",
      "epoch: 5 loss: 0.848296      0\n",
      "epoch: 6 loss: 0.832238      0\n",
      "epoch: 7 loss: 0.810568      0\n",
      "epoch: 8 loss: 0.879546      0\n",
      "epoch: 9 loss: 0.755424      0\n",
      "epoch: 10 loss: 0.752554      0\n",
      "epoch: 11 loss: 0.770882      0\n",
      "epoch: 12 loss: 0.774271      0\n",
      "epoch: 13 loss: 0.769075      0\n",
      "epoch: 14 loss: 0.771265      0\n",
      "epoch: 15 loss: 0.774734      0\n",
      "epoch: 16 loss: 0.741923      0\n",
      "epoch: 17 loss: 0.730367      0\n",
      "epoch: 18 loss: 0.737697      0\n",
      "epoch: 19 loss: 0.770083      0\n",
      "epoch: 20 loss: 0.787300      0\n",
      "epoch: 21 loss: 0.778304      0\n",
      "epoch: 22 loss: 0.752400      0\n",
      "epoch: 23 loss: 0.724833      0\n",
      "epoch: 24 loss: 0.685439      0\n",
      "epoch: 25 loss: 0.703381      0\n",
      "epoch: 26 loss: 0.724779      0\n",
      "epoch: 27 loss: 0.792020      0\n",
      "epoch: 28 loss: 0.641224      0\n",
      "epoch: 29 loss: 0.588327      0\n",
      "epoch: 30 loss: 0.706474      0\n",
      "epoch: 31 loss: 0.639294      0\n",
      "epoch: 32 loss: 0.675610      0\n",
      "epoch: 33 loss: 0.621940      0\n",
      "epoch: 34 loss: 0.693341      0\n",
      "epoch: 35 loss: 0.683586      0\n",
      "epoch: 36 loss: 0.618279      0\n",
      "epoch: 37 loss: 0.626597      0\n",
      "epoch: 38 loss: 0.676693      0\n",
      "epoch: 39 loss: 0.691065      0\n",
      "epoch: 40 loss: 0.672113      0\n",
      "epoch: 41 loss: 0.626326      0\n",
      "epoch: 42 loss: 0.720131      0\n",
      "epoch: 43 loss: 0.629474      0\n",
      "epoch: 44 loss: 0.636332      0\n",
      "epoch: 45 loss: 0.648539      0\n",
      "epoch: 46 loss: 0.597882      0\n",
      "epoch: 47 loss: 0.681085      0\n",
      "epoch: 48 loss: 0.673330      0\n",
      "epoch: 49 loss: 0.699241      0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (stack): Sequential(\n",
       "    (0): Conv1d(300, 30, kernel_size=(1,), stride=(1,))\n",
       "    (1): ELU(alpha=1.0)\n",
       "    (2): Conv1d(30, 40, kernel_size=(3,), stride=(1,))\n",
       "    (3): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): ELU(alpha=1.0)\n",
       "    (5): Conv1d(40, 1, kernel_size=(3,), stride=(1,))\n",
       "    (6): ELU(alpha=1.0)\n",
       "    (7): Flatten(start_dim=1, end_dim=-1)\n",
       "    (8): Linear(in_features=17, out_features=20, bias=True)\n",
       "    (9): ELU(alpha=1.0)\n",
       "    (10): Linear(in_features=20, out_features=3, bias=True)\n",
       "    (11): ELU(alpha=1.0)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()\n",
    "\n",
    "# loss_function = t.nn.NLLLoss()\n",
    "loss_function = t.nn.CrossEntropyLoss()\n",
    "optimizer = t.optim.Adam(model.parameters(), lr=0.001)\n",
    "max_epochs = 50\n",
    "batch_size = 400\n",
    "_train = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "for i in range(0, max_epochs):\n",
    "    for batch, (b_X, b_Y) in enumerate(_train):\n",
    "        optimizer.zero_grad()\n",
    "        b_ans = model.forward(b_X)\n",
    "        loss = loss_function(b_ans, b_Y.flatten())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch == 0:\n",
    "            loss, current = loss.item(), batch\n",
    "            print(f\"epoch: {i} loss: {loss:>7f}  {current:>5d}\")\n",
    "    \n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = TextDataset(test[['text']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2001e-01,  1.1845e-01,  2.3413e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-6.8741e-01, -1.9885e-02,  6.4766e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.3924e-01, -3.2615e-02, -5.5659e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 1.8861e-01,  2.0111e-02,  2.0082e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 1.1401e-01, -8.4807e-03, -1.9653e-02,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-1.9603e-02,  6.4655e-03,  1.7885e-04,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "_data = DataLoader(x_test)\n",
    "result=[]\n",
    "for x in _data:\n",
    "    result.append(model(x).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.argmax(result, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = {\n",
    "    0: 'positive',\n",
    "    1: 'negative',\n",
    "    2: 'neutral'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'textID': test['textID'],\n",
    "    'sentiment': [mp[item] for item in res.astype(int).reshape(-1)]\n",
    "}).to_csv('data/submissions/4-neural-network.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
